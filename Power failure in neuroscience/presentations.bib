@article{chambers2013,
  title = {Registered {{Reports}}: {{A}} New Publishing Initiative at {{Cortex}}},
  shorttitle = {Registered {{Reports}}},
  author = {Chambers, Christopher D.},
  date = {2013},
  journaltitle = {Cortex: A Journal Devoted to the Study of the Nervous System and Behavior},
  volume = {49},
  number = {3},
  pages = {609--610},
  publisher = {Elsevier Masson SAS},
  location = {France},
  issn = {1973-8102},
  doi = {10.1016/j.cortex.2012.12.016},
  abstract = {The Registered Reports format has several attractive characteristics. First, it will be immune to publication bias because the decision to accept or reject manuscripts will be based on the significance of the research question and validity of the methods, never on whether results are novel or statistically significant. Second, by requiring authors to adhere to a pre-approved methodology and analysis pipeline, it will instantly prevent a host of questionable but common practices that promote false discoveries, including p value fishing, creative outlier exclusion, and selective reporting of analyses. Third, by requiring an a priori power analysis, including a minimum power level of 90\%, false negatives will be greatly reduced compared with standard empirical reports. Not all modes of scientific investigation will be compatible with the Registered Reports initiative, and we will be maintaining all of our existing publishing options. However, for most types of studies, Registered Reports will not outlaw serendipity or hinder legitimate scientific flexibility. Authors will be welcome to include post hoc analyses that were not mentioned in pre-registered submissions. Such analyses will simply be distinguished from those that were planned in advance, and authors will not be able to revise their hypotheses to predict unexpected outcomes. In the coming months we will formulate detailed author and reviewer guidelines for Registered Reports. We look forward to launching this exciting new platform and welcome contributions to the discussion from our readers and the broader scientific community. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Nervous System,Neurosciences,Scientific Communication},
  file = {C\:\\Users\\psyuser\\Zotero\\storage\\PYLPKHUI\\Chambers_2013_Registered Reports.pdf;C\:\\Users\\psyuser\\Zotero\\storage\\8AV25VL7\\2013-10004-004.html}
}

@article{opensciencecollaboration2015,
  title = {Estimating the Reproducibility of Psychological Science},
  author = {{Open Science Collaboration}},
  date = {2015-08-28},
  journaltitle = {Science},
  volume = {349},
  number = {6251},
  pages = {aac4716},
  publisher = {American Association for the Advancement of Science},
  doi = {10.1126/science.aac4716},
  abstract = {Reproducibility is a defining feature of science, but the extent to which it characterizes current research is unknown. We conducted replications of 100 experimental and correlational studies published in three psychology journals using high-powered designs and original materials when available. Replication effects were half the magnitude of original effects, representing a substantial decline. Ninety-seven percent of original studies had statistically significant results. Thirty-six percent of replications had statistically significant results; 47\% of original effect sizes were in the 95\% confidence interval of the replication effect size; 39\% of effects were subjectively rated to have replicated the original result; and if no bias in original results is assumed, combining original and replication results left 68\% with statistically significant effects. Correlational tests suggest that replication success was better predicted by the strength of original evidence than by characteristics of the original and replication teams.},
  file = {C:\Users\psyuser\Zotero\storage\ARL3TR24\Open Science Collaboration_2015_Estimating the reproducibility of psychological science.pdf}
}

@article{sullivan2007,
  title = {Spurious {{Genetic Associations}}},
  author = {Sullivan, Patrick F.},
  date = {2007-05},
  journaltitle = {Biological Psychiatry},
  shortjournal = {Biological Psychiatry},
  volume = {61},
  number = {10},
  pages = {1121--1126},
  issn = {00063223},
  doi = {10.1016/j.biopsych.2006.11.010},
  abstract = {Background: Genetic association studies are widely used in biomedical research and yet only a minority of positive findings stand the test of replication. I explored the capacity of association studies to produce false positive findings and the impact of various definitions of replication. Methods: Genetically realistic simulation data of a typical genotyping/analytic approach for 10 single nucleotide polymorphisms (SNPs) in COMT, a commonly studied candidate gene. Results: Candidate gene studies like those simulated here are highly likely to produce one or more false positive findings at ␣ Յ .05, the pattern of findings can often be “compelling” or “intriguing,” and false positive findings propagate and confuse the literature unless the definition of replication is precise. Conclusions: Findings from single association studies constitute “tentative knowledge” and must be interpreted with exceptional caution. For the association method to function as intended, every statistical comparison must be tracked and reported, and integrated replication is essential. Precise replication (the same SNPs, phenotype, and direction of association) is required in the interpretation of multiple association studies.},
  language = {en},
  file = {C:\Users\psyuser\Zotero\storage\E7VX942V\Sullivan - 2007 - Spurious Genetic Associations.pdf}
}

@book{wheeler2014,
  title = {Data {{Science Study Protocols}} for {{Investigating Lifetime}} and {{Degradation}} of {{PV Technology Systems}}},
  author = {Wheeler, Nicholas and Xu, Yifan and Gok, Abdulkerim and Kidd, Ian and Bruckman, Laura and Sun, Jiayang and French, Roger},
  date = {2014-06-01},
  abstract = {The reliability of photovoltaic (PV) technology systems is a major concern to the PV industry, and the focus of much research activity. To ensure that these efforts do not result in wasted resources, it is critical that attention be paid to the statistical significance of generated data. With pre-knowledge of certain aspects of a proposed study, data science study protocols may be specified that aim to determine required sample size to adequately address the research objective. We describe the process of designing such a study protocol, based upon expected uncertainties calculated from a pilot study. This represents a methodological approach to defining scientific studies that balances cost against potential information yield. Index Terms — photovoltaic systems, regression analysis, enterprise resource planning, knowledge management},
  file = {C:\Users\psyuser\Zotero\storage\URVQLJPC\Wheeler et al_2014_Data Science Study Protocols for Investigating Lifetime and Degradation of PV.pdf}
}
